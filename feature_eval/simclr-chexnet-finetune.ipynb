{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport sys\nimport numpy as np\nimport os\nimport yaml\nimport matplotlib.pyplot as plt\nimport torchvision","metadata":{"id":"YUemQib7ZE4D","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:32:35.109775Z","iopub.execute_input":"2022-02-15T03:32:35.110347Z","iopub.status.idle":"2022-02-15T03:32:36.728007Z","shell.execute_reply.started":"2022-02-15T03:32:35.110238Z","shell.execute_reply":"2022-02-15T03:32:36.727246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"id":"WSgRE1CcLqdS","outputId":"48a2ae15-f672-495b-8d43-9a23b85fa3b8","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:32:36.729854Z","iopub.execute_input":"2022-02-15T03:32:36.730124Z","iopub.status.idle":"2022-02-15T03:32:58.681066Z","shell.execute_reply.started":"2022-02-15T03:32:36.730089Z","shell.execute_reply":"2022-02-15T03:32:58.679965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_file_id_by_model(folder_name):\n    file_id = {'resnet18_100-epochs_stl10': '14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF',\n             'resnet18_100-epochs_cifar10': '1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C',\n             'resnet50_50-epochs_stl10': '1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu'}\n    return file_id.get(folder_name, \"Model not found.\")","metadata":{"id":"NOIJEui1ZziV","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:32:58.683675Z","iopub.execute_input":"2022-02-15T03:32:58.683982Z","iopub.status.idle":"2022-02-15T03:32:58.690843Z","shell.execute_reply.started":"2022-02-15T03:32:58.683944Z","shell.execute_reply":"2022-02-15T03:32:58.690172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_name = 'resnet50_50-epochs_stl10'\nfile_id = get_file_id_by_model(folder_name)\nprint(folder_name, file_id)","metadata":{"id":"G7YMxsvEZMrX","outputId":"59475430-69d2-45a2-b61b-ae755d5d6e88","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:32:58.693569Z","iopub.execute_input":"2022-02-15T03:32:58.69393Z","iopub.status.idle":"2022-02-15T03:32:58.701866Z","shell.execute_reply.started":"2022-02-15T03:32:58.69381Z","shell.execute_reply":"2022-02-15T03:32:58.700886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir /content/images\n# %cd /content/images\n# !pip install -q kaggle\n# ! cp /content/kaggle.json ~/.kaggle/\n# !kaggle datasets download nih-chest-xrays/data\n# !unzip -j data.zip -d .\n# !rm data.zip\n# %cd /content/","metadata":{"id":"PWZ8fet_YoJm","outputId":"ca3f5e41-db73-4240-ab2e-c72ebd3d145c","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:32:58.703701Z","iopub.execute_input":"2022-02-15T03:32:58.703914Z","iopub.status.idle":"2022-02-15T03:32:58.710764Z","shell.execute_reply.started":"2022-02-15T03:32:58.703887Z","shell.execute_reply":"2022-02-15T03:32:58.709935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchinfo wandb\n\n!wandb login 606ef0ddb19fbf179952be1ae9823b40ec33b3b7\nimport wandb","metadata":{"id":"MNEJDDihiAT8","outputId":"ec39d358-6b65-4296-d294-b38a9ef41eaa","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:32:58.713437Z","iopub.execute_input":"2022-02-15T03:32:58.713739Z","iopub.status.idle":"2022-02-15T03:33:09.539272Z","shell.execute_reply.started":"2022-02-15T03:32:58.713706Z","shell.execute_reply":"2022-02-15T03:33:09.538456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# user =\"vidura\"\n# project = \"medicap-contrastive\"\n# run = \"2x9w9qwt\"\n\n# best_model = wandb.restore('last_checkpoint.pth.tar', run_path=\"{}/{}/{}\".format(user,project,run))","metadata":{"id":"WXDMFUSxiAT9","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:09.540734Z","iopub.execute_input":"2022-02-15T03:33:09.540984Z","iopub.status.idle":"2022-02-15T03:33:09.544699Z","shell.execute_reply.started":"2022-02-15T03:33:09.540951Z","shell.execute_reply":"2022-02-15T03:33:09.544052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id = wandb.util.generate_id()\nprint(id)","metadata":{"id":"_44Yf2P5iAT-","outputId":"b0b5d8b2-6883-4967-e7da-24681e3350a5","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:09.546659Z","iopub.execute_input":"2022-02-15T03:33:09.547124Z","iopub.status.idle":"2022-02-15T03:33:09.559062Z","shell.execute_reply.started":"2022-02-15T03:33:09.547081Z","shell.execute_reply":"2022-02-15T03:33:09.558345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(id=id, project=\"medicap-contrastive-finetune\", entity=\"raveen_hansika\", resume=True)","metadata":{"id":"fw99i-FWiAT_","outputId":"04ce32b8-7bd4-4c97-ac6c-39f7d50d3ca2","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:09.560369Z","iopub.execute_input":"2022-02-15T03:33:09.560684Z","iopub.status.idle":"2022-02-15T03:33:17.096548Z","shell.execute_reply.started":"2022-02-15T03:33:09.560634Z","shell.execute_reply":"2022-02-15T03:33:17.095842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nimport torch.nn as nn\nimport torch\nimport sys\nimport numpy as np\nimport os\nimport yaml\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torch.utils.data import Dataset\nfrom tqdm import tqdm\nfrom PIL import Image\n","metadata":{"id":"3_nypQVEv-hn","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:17.099963Z","iopub.execute_input":"2022-02-15T03:33:17.100355Z","iopub.status.idle":"2022-02-15T03:33:17.105648Z","shell.execute_reply.started":"2022-02-15T03:33:17.100317Z","shell.execute_reply":"2022-02-15T03:33:17.104963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Using device:\", device)","metadata":{"id":"lDfbL3w_Z0Od","outputId":"21be746d-bb94-4099-8a75-150fdd45bbd3","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:17.106606Z","iopub.execute_input":"2022-02-15T03:33:17.107069Z","iopub.status.idle":"2022-02-15T03:33:17.158044Z","shell.execute_reply.started":"2022-02-15T03:33:17.107032Z","shell.execute_reply":"2022-02-15T03:33:17.157349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNet121(nn.Module):\n    \"\"\"Model modified.\n\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n\n    \"\"\"\n    def __init__(self,pretrained=True, num_classes=14):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=pretrained)\n\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n                nn.Linear(num_ftrs, num_classes),\n                nn.Sigmoid()\n            )\n\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x\n\n\nCLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia',\"No findings\"]\nclass ContrastiveDataset(Dataset):\n    def __init__(self, data_dir, split, transform=None):\n        \"\"\"\n        Args:\n            data_dir: path to image directory.\n            image_list_file: path to the file containing images\n                with corresponding labels.\n            transform: optional transform to be applied on a sample.\n        \"\"\"\n        image_names = []\n        labels = []\n        with open(split, \"r\") as f:\n            for line in f:\n                items = line.split()\n                image_name= items[0]\n                label = items[1:]\n                label = [int(i) for i in label]\n                image_name = os.path.join(data_dir, image_name)\n                image_names.append(image_name)\n                labels.append(label)\n        self.image_names = image_names\n        self.labels = labels\n        self.transform = transform\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item\n\n        Returns:\n            image and its labels\n        \"\"\"\n        image_name = self.image_names[index]\n        image = Image.open(image_name).convert('RGB')\n        label = self.labels[index]\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image, torch.FloatTensor(label)\n\n    def __len__(self):\n        return len(self.image_names)\n","metadata":{"id":"alQjMAAXiAUB","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:17.159481Z","iopub.execute_input":"2022-02-15T03:33:17.159816Z","iopub.status.idle":"2022-02-15T03:33:17.176415Z","shell.execute_reply.started":"2022-02-15T03:33:17.159781Z","shell.execute_reply":"2022-02-15T03:33:17.175702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.transforms import transforms\n\n\ndef get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n    train_dataset = datasets.STL10('./data', split='train', download=download,\n                                  transform=transforms.ToTensor())\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n                            num_workers=0, drop_last=False, shuffle=shuffle)\n  \n    test_dataset = datasets.STL10('./data', split='test', download=download,\n                                  transform=transforms.ToTensor())\n\n    test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n                            num_workers=10, drop_last=False, shuffle=shuffle)\n    return train_loader, test_loader\n\ndef get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n    train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n                                  transform=transforms.ToTensor())\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n                            num_workers=0, drop_last=False, shuffle=shuffle)\n  \n    test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n                                  transform=transforms.ToTensor())\n\n    test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n                            num_workers=10, drop_last=False, shuffle=shuffle)\n    return train_loader, test_loader\n\ndef get_medicap_contrastive_transform(size):\n        data_transforms = transforms.Compose([transforms.Resize(size),\n                                              transforms.ToTensor()])\n        return data_transforms\ndef get_chestxray_data_loaders(root_folder, shuffle=False, batch_size=256):\n    train_dataset = ContrastiveDataset(root_folder,split=\"/kaggle/input/chexnet-file-list/train_list.txt\",transform=get_medicap_contrastive_transform(256))\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n                            num_workers=0, drop_last=False, shuffle=shuffle)\n  \n    test_dataset = ContrastiveDataset(root_folder,split=\"/kaggle/input/chexnet-file-list/val_list.txt\",transform=get_medicap_contrastive_transform(256))\n\n    test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n                            num_workers=10, drop_last=False, shuffle=shuffle)\n    return train_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:33:17.178977Z","iopub.execute_input":"2022-02-15T03:33:17.17919Z","iopub.status.idle":"2022-02-15T03:33:17.193995Z","shell.execute_reply.started":"2022-02-15T03:33:17.179166Z","shell.execute_reply":"2022-02-15T03:33:17.193131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Struct:\n    def __init__(self, **entries):\n        self.__dict__.update(entries)\n        \nconfig = {\n  \"arch\":\"chexnet\",\n  \"dataset_name\":\"chexnet\",\n  \"root_folder\":\"/kaggle/input/data/\",\n  \"result_dir\":\"./\"\n}\nconfig = Struct(**config)\n\nbest_valid_loss = np.inf","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:33:17.195201Z","iopub.execute_input":"2022-02-15T03:33:17.195715Z","iopub.status.idle":"2022-02-15T03:33:17.206284Z","shell.execute_reply.started":"2022-02-15T03:33:17.195677Z","shell.execute_reply":"2022-02-15T03:33:17.205508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.arch == 'resnet18':\n    model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\nelif config.arch == 'resnet50':\n    model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)\nelif(config.arch == \"chexnet\"):\n    model = DenseNet121(pretrained=False, num_classes=14)","metadata":{"id":"a18lPD-tIle6","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:17.207663Z","iopub.execute_input":"2022-02-15T03:33:17.208478Z","iopub.status.idle":"2022-02-15T03:33:17.450087Z","shell.execute_reply.started":"2022-02-15T03:33:17.208443Z","shell.execute_reply":"2022-02-15T03:33:17.449215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/input/chexnet-simclr-model/best_checkpoint.pth.tar', map_location=device)\nstate_dict = checkpoint['state_dict']\n\nfor k in list(state_dict.keys()):\n\n    if k.startswith('backbone.'):\n        if k.startswith('backbone') and not (k.startswith('backbone.fc') or k.startswith('backbone.densenet121.classifier')):\n            # remove prefix\n            state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n    del state_dict[k]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('resume model from', checkpoint['epoch'])","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:33:22.001015Z","iopub.execute_input":"2022-02-15T03:33:22.001351Z","iopub.status.idle":"2022-02-15T03:33:22.008993Z","shell.execute_reply.started":"2022-02-15T03:33:22.00128Z","shell.execute_reply":"2022-02-15T03:33:22.006613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log = model.load_state_dict(state_dict, strict=False)\nassert log.missing_keys == ['densenet121.classifier.0.weight', 'densenet121.classifier.0.bias']","metadata":{"id":"VVjA83PPJYWl","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:22.010471Z","iopub.execute_input":"2022-02-15T03:33:22.011162Z","iopub.status.idle":"2022-02-15T03:33:22.116654Z","shell.execute_reply.started":"2022-02-15T03:33:22.01112Z","shell.execute_reply":"2022-02-15T03:33:22.114446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.dataset_name == 'cifar10':\n    train_loader, test_loader = get_cifar10_data_loaders(download=True)\nelif config.dataset_name == 'stl10':\n    train_loader, test_loader = get_stl10_data_loaders(download=True)\nelif config.dataset_name == 'chexnet':\n    train_loader, test_loader = get_chestxray_data_loaders(config.root_folder)\nprint(\"Dataset:\", config.dataset_name)","metadata":{"id":"_GC0a14uWRr6","outputId":"ccfc8c32-3b23-4005-f739-9e2b85ce7aa2","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:22.120862Z","iopub.execute_input":"2022-02-15T03:33:22.122769Z","iopub.status.idle":"2022-02-15T03:33:22.802568Z","shell.execute_reply.started":"2022-02-15T03:33:22.122728Z","shell.execute_reply":"2022-02-15T03:33:22.801806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# freeze all layers but the last fc\nfor name, param in model.named_parameters():\n    if name not in ['densenet121.classifier.0.weight', 'densenet121.classifier.0.bias']:\n        param.requires_grad = False\n\nparameters = list(filter(lambda p: p.requires_grad, model.parameters()))\nassert len(parameters) == 2  # fc.weight, fc.bias","metadata":{"id":"pYT_KsM0Mnnr","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:22.803782Z","iopub.execute_input":"2022-02-15T03:33:22.804547Z","iopub.status.idle":"2022-02-15T03:33:22.814937Z","shell.execute_reply.started":"2022-02-15T03:33:22.804506Z","shell.execute_reply":"2022-02-15T03:33:22.814094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\ncriterion = torch.nn.BCELoss().to(device)","metadata":{"id":"aPVh1S_eMRDU","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:22.816123Z","iopub.execute_input":"2022-02-15T03:33:22.816411Z","iopub.status.idle":"2022-02-15T03:33:22.830406Z","shell.execute_reply.started":"2022-02-15T03:33:22.816372Z","shell.execute_reply":"2022-02-15T03:33:22.829699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(output, target):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = torch.sum(target,dim=1)\n        batch_size = target.size(0)\n        pred_labels = []\n        for i, x in enumerate(output):\n            labels = x.topk(int(maxk[i].item())).indices\n            labels = labels.unsqueeze(0)\n            pred_labels.append(torch.zeros(labels.size(0), target.size(1)).to(device).scatter_(1, labels, 1.).to(device))\n        pred = torch.cat(pred_labels)\n        mask = target > 0\n        a = torch.masked_select(pred,mask)\n        return (torch.sum(a)/torch.sum(target)).item()*100","metadata":{"id":"edr6RhP2PdVq","editable":false,"execution":{"iopub.status.busy":"2022-02-15T03:33:22.834825Z","iopub.execute_input":"2022-02-15T03:33:22.836764Z","iopub.status.idle":"2022-02-15T03:33:22.848941Z","shell.execute_reply.started":"2022-02-15T03:33:22.836726Z","shell.execute_reply":"2022-02-15T03:33:22.848071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(state, filename='checkpoint.pth.tar'):\n    torch.save(state, filename)\n    wandb.save(filename, policy=\"now\")\n    print(\"save\", filename)","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:33:22.850364Z","iopub.execute_input":"2022-02-15T03:33:22.850627Z","iopub.status.idle":"2022-02-15T03:33:22.858586Z","shell.execute_reply.started":"2022-02-15T03:33:22.850571Z","shell.execute_reply":"2022-02-15T03:33:22.857953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 7\nwandb.watch(model)\nmodel = model.to(device)\nstart_epoch = checkpoint['epoch'] + 1\nbest_valid_loss = checkpoint['best_valid_loss']\noptimizer.load_state_dict(checkpoint['optimizer'])\n\nfor epoch in range(start_epoch, epochs + 1):\n    print(torch.cuda.current_device(), torch.cuda.get_device_name(0), \"epoch\", epoch)\n    \n    top1_train_accuracy = 0\n    train_loss =0\n    valid_loss =0\n    model.train()\n    for counter, (x_batch, y_batch) in enumerate(tqdm(train_loader)):\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n        logits = model(x_batch)\n        loss = criterion(logits, y_batch)\n        train_loss +=loss.item()\n        top1 = accuracy(logits, y_batch)\n        top1_train_accuracy += top1\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    top1_train_accuracy /= (counter + 1)\n    top1_accuracy = 0\n    model.eval()\n    with torch.no_grad():\n        for counter, (x_batch, y_batch) in enumerate(tqdm(test_loader)):\n            x_batch = x_batch.to(device)\n            y_batch = y_batch.to(device)\n\n            logits = model(x_batch)\n            loss = criterion(logits, y_batch)\n            valid_loss +=loss.item()\n            top1 = accuracy(logits, y_batch)\n            top1_accuracy += top1\n            \n    train_loss = train_loss/(len(train_loader))\n    valid_loss = valid_loss/(len(test_loader))\n    \n    if(valid_loss < best_valid_loss):\n        best_valid_loss = valid_loss\n        save_checkpoint({\n                'epoch': epoch,\n                'best_valid_loss': best_valid_loss,\n                'arch': config.arch,\n                'state_dict': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, filename=os.path.join(config.result_dir, 'best_checkpoint.pth.tar'))\n        \n    save_checkpoint({\n                'epoch': epoch,\n                'best_valid_loss': best_valid_loss,\n                'arch': config.arch,\n                'state_dict': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, filename=os.path.join(config.result_dir, 'last_checkpoint.pth.tar'))\n    \n    top1_accuracy /= (counter + 1)\n    wandb.log(\n      {\"epoch\":epoch,\n       \"train loss\":train_loss,\n       \"valid loss\":valid_loss,\n       \"Top1 Train accuracy\":top1_train_accuracy,\n       \"Top1 Test accuracy\":top1_accuracy\n       })\n    print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy}\\tTop1 Test accuracy: {top1_accuracy}\\tTrain_loss: {train_loss}\\tValid_loss: {valid_loss}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-15T03:33:22.859396Z","iopub.execute_input":"2022-02-15T03:33:22.859724Z","iopub.status.idle":"2022-02-15T06:07:17.05041Z","shell.execute_reply.started":"2022-02-15T03:33:22.859688Z","shell.execute_reply":"2022-02-15T06:07:17.049556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"dtYqHZirMNZk","editable":false},"execution_count":null,"outputs":[]}]}